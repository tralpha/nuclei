{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "test_dirs = os.listdir(\"input/stage1_test\")\n",
    "test_filenames=[\"input/stage1_test/\"+file_id+\"/images/\"+file_id+\".png\" for file_id in test_dirs]\n",
    "test_images=[cv2.imread(imagefile) for imagefile in test_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of operations to be performed on each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(img_rgb):\n",
    "    #green channel happends to produce slightly better results\n",
    "    #than the grayscale image and other channels\n",
    "    img_gray=img_rgb[:,:,1]#cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    #morphological opening (size tuned on training data)\n",
    "    circle7=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7))\n",
    "    img_open=cv2.morphologyEx(img_gray, cv2.MORPH_OPEN, circle7)\n",
    "    #Otsu thresholding\n",
    "    img_th=cv2.threshold(img_open,0,255,cv2.THRESH_OTSU)[1]\n",
    "    #Invert the image in case the objects of interest are in the dark side\n",
    "    if(np.sum(img_th==255)>np.sum(img_th==0)):\n",
    "        img_th=cv2.bitwise_not(img_th)\n",
    "    #second morphological opening (on binary image this time)\n",
    "    bin_open=cv2.morphologyEx(img_th, cv2.MORPH_OPEN, circle7) \n",
    "    #connected components\n",
    "    cc=cv2.connectedComponents(bin_open)[1]\n",
    "    #cc=segment_on_dt(bin_open,20)\n",
    "    return cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing output for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_connected_components=[process(img)  for img in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rle_encoding(cc):\n",
    "    values=list(np.unique(cc))\n",
    "    values.remove(0)\n",
    "    RLEs=[]\n",
    "    for v in values:\n",
    "        dots = np.where(cc.T.flatten() == v)[0]\n",
    "        run_lengths = []\n",
    "        prev = -2\n",
    "        for b in dots:\n",
    "            if (b>prev+1):\n",
    "                run_lengths.extend((b + 1, 0))\n",
    "            run_lengths[-1] += 1\n",
    "            prev = b\n",
    "        RLEs.append(run_lengths)\n",
    "    return RLEs\n",
    "\n",
    "# test_RLEs=[rle_encoding(cc) for cc in test_connected_components]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RLE Encoding\n",
    "Also known as Run length encoding, a way to encode segmentation information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
